{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ea6ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nN0 range:[0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 1, 2, 5, 10, 25, 50, 100]\\ngamma range: [0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.9]\\n\\nNúmero de batalhas: 10k\\nneptune\\nAction space: 4 moves + 5 switches\\npoke-env installed in C:\\\\Users\\\\-\\\\anaconda3\\\\envs\\\\poke_env\\\\lib\\\\site-packages\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "N0 range:[0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 1, 2, 5, 10, 25, 50, 100]\n",
    "gamma range: [0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "Número de batalhas: 10k\n",
    "neptune\n",
    "Action space: 4 moves + 5 switches\n",
    "poke-env installed in C:\\\\Users\\\\-\\\\anaconda3\\\\envs\\\\poke_env\\\\lib\\\\site-packages\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7340ee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/leolellisr/rl-pokeenv/e/RLPOK-33\n",
      "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from gym import spaces\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.playerMC import Player as PlayerMC\n",
    "\n",
    "from poke_env.player.player import Player \n",
    "#from poke_env.player.random_player import RandomPlayer\n",
    "\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "np.random.seed(0)\n",
    "#loop = asyncio.get_event_loop()\n",
    "import neptune.new as neptune\n",
    "run = neptune.init(project='leolellisr/rl-pokeenv',\n",
    "                   api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI1NjY1YmJkZi1hYmM5LTQ3M2QtOGU1ZC1iZTFlNWY4NjE1NDQifQ==')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "903ea52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_to_id(name):\n",
    "    if(name == 'venusaur'): return 0\n",
    "    if(name == 'pikachuoriginal'): return 1 \n",
    "    if(name == 'tauros'): return 2 \n",
    "    if(name == 'sirfetchd'): return 3 \n",
    "    if(name == 'blastoise'): return 4 \n",
    "    if(name == 'charizard'): return 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139879a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxDamagePlayer(Player):\n",
    "    def choose_move(self, battle):\n",
    "        # If the player can attack, it will\n",
    "        if battle.available_moves:\n",
    "            # Finds the best move among available ones\n",
    "            #print(battle.available_moves[0])\n",
    "            best_move = max(battle.available_moves, key=lambda move: move.base_power)\n",
    "            return self.create_order(best_move)\n",
    "\n",
    "        # If no attack is available, a random switch will be made\n",
    "        else:\n",
    "            return self.choose_random_move(battle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0508551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPlayer(PlayerMC):\n",
    "    def choose_move(self, battle):\n",
    "        # In the 1st state of all we don't append yet;\n",
    "        # Other states: using previous state and action with actual reward (actual battle) \n",
    "        if self.previous_action != -10: self.episode.append((self.previous_state, self.previous_action, self.compute_reward(battle)))\n",
    "            \n",
    "        # Getting state s (-> embed battle)\n",
    "        s = self.embed_battle(battle)\n",
    "        # 1st move will be random wout policy    \n",
    "        if(self.aux == 0):\n",
    "            self.aux = 1\n",
    "            action = np.random.choice(self.action_space)\n",
    "\n",
    "        # Other moves have policy    \n",
    "        else: action = np.random.choice(self.action_space, p=self.policy(s))\n",
    "\n",
    "        # Saving action and state to append later. We can compute the reward only after the move    \n",
    "        self.previous_action = action\n",
    "        self.previous_state = s\n",
    "\n",
    "        # Prints for debuging    \n",
    "        #print(battle.available_moves)\n",
    "        #print(f\"Choosed action int: {action}\")        \n",
    "        #print(\"Return: \", self.policy(s))\n",
    "\n",
    "        # Choose move according to action index\n",
    "        if action == -1:\n",
    "            return ForfeitBattleOrder()\n",
    "        elif (\n",
    "            action < 4\n",
    "            and action < len(battle.available_moves)\n",
    "            and not battle.force_switch\n",
    "        ):\n",
    "            return self.create_order(battle.available_moves[action])\n",
    "        elif 0 <= action - 4 < len(battle.available_switches):\n",
    "            return self.create_order(battle.available_switches[action - 4])\n",
    "        else:\n",
    "            return self.choose_random_move(battle)\n",
    "        \n",
    "        return self.create_order(action)\n",
    "\n",
    "    # the embed battle is our state\n",
    "    # 10 factors: 4 moves base power, 4 moves multipliers, active pokemon and active opponent pokemon \n",
    "    def embed_battle(self, battle):\n",
    "        # -1 indicates that the move does not have a base power or not available\n",
    "        active_pokemon = [mon for mon in battle.team.values() if mon._active]\n",
    "        name_id = name_to_id(active_pokemon[0]._species)\n",
    "        #print(active_pokemon)\n",
    "        \n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling \n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                )\n",
    "\n",
    "        # how many pokemons have fainted in each team\n",
    "        remaining_mon_team = (\n",
    "            len([mon for mon in battle.team.values() if mon.fainted]) / 6\n",
    "        )\n",
    "        remaining_mon_opponent = (\n",
    "            len([mon for mon in battle.opponent_team.values() if mon.fainted]) / 6\n",
    "        )\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        x = np.around(np.concatenate(\n",
    "            [\n",
    "                 np.array([name_id]), moves_base_power,\n",
    "                moves_dmg_multiplier,\n",
    "                [remaining_mon_team, remaining_mon_opponent]\n",
    "            ])\n",
    "        ,decimals=2)\n",
    "        \n",
    "        # Convert to string so we can use as hash\n",
    "        return ' '.join(str(i) for i in x)\n",
    "        \n",
    "\n",
    "    # Computing rewards\n",
    "    def reward_computing_helper(\n",
    "        self,\n",
    "        battle: AbstractBattle,\n",
    "        *,\n",
    "        fainted_value: float = 0.15, \n",
    "        hp_value: float = 0.15,      \n",
    "        number_of_pokemons: int = 6,\n",
    "        starting_value: float = 0.0,\n",
    "        status_value: float = 0.15, \n",
    "        victory_value: float = 1.0\n",
    "    ) -> float:\n",
    "        \n",
    "        # 1st compute\n",
    "        if battle not in self._reward_buffer:\n",
    "            self._reward_buffer[battle] = starting_value\n",
    "        current_value = 0\n",
    "        \n",
    "        # Verify if pokemon have fainted or have status\n",
    "        for mon in battle.team.values():\n",
    "            current_value += mon.current_hp_fraction * hp_value\n",
    "            if mon.fainted:\n",
    "                current_value -= fainted_value\n",
    "            elif mon.status is not None:\n",
    "                current_value -= status_value\n",
    "\n",
    "        current_value += (number_of_pokemons - len(battle.team)) * hp_value\n",
    "\n",
    "        # Verify if opponent pokemon have fainted or have status\n",
    "        for mon in battle.opponent_team.values():\n",
    "            current_value -= mon.current_hp_fraction * hp_value\n",
    "            if mon.fainted:\n",
    "                current_value += fainted_value\n",
    "            elif mon.status is not None:\n",
    "                current_value += status_value\n",
    "\n",
    "        current_value -= (number_of_pokemons - len(battle.opponent_team)) * hp_value\n",
    "\n",
    "        # Verify if we won or lost\n",
    "        if battle.won:\n",
    "            current_value += victory_value\n",
    "        elif battle.lost:\n",
    "            current_value -= victory_value\n",
    "\n",
    "        # Value to return\n",
    "        to_return = current_value - self._reward_buffer[battle]\n",
    "        self._reward_buffer[battle] = current_value\n",
    "        #self.reward_per_battle.append(current_value)\n",
    "        #print(self.reward_per_battle)\n",
    "        run[f'N0: {self.n0} gamma: {self.gamma} reward_buffer'].log(current_value)\n",
    "        run[f'N0: {self.n0} gamma: {self.gamma} reward returned'].log(to_return)\n",
    "        return to_return\n",
    "    \n",
    "    \n",
    "    # Calling reward_computing_helper\n",
    "    def compute_reward(self, battle) -> float:\n",
    "        return self.reward_computing_helper(            \n",
    "            battle, fainted_value=2, hp_value=1, status_value=1, victory_value=15\n",
    "        )\n",
    "\n",
    "    # Battle (episode) has finished\n",
    "    def _battle_finished_callback(self, battle):\n",
    "        reward_array = [reward for state,action,reward in self.episode]\n",
    "        t_array = range(len(self.episode))\n",
    "        returnGt = sum([reward*pow(self.gamma, t) for reward, t in zip(reward_array, t_array)]) \n",
    "        run[f'N0: {self.n0} gamma: {self.gamma} Gt'].log(returnGt)\n",
    "        \n",
    "        # Computing Q and N\n",
    "        for state,action,reward in self.episode:\n",
    "            \n",
    "            if state not in self.visited_states:\n",
    "                self.N[state][action] += 1\n",
    "                # incremental update of Q value is more efficient than keeping a record of all rewards\n",
    "                # and averaging after every new reward\n",
    "                run[f'N0: {self.n0} gamma: {self.gamma} reward computed'].log(reward)\n",
    "                # discount_factor = 1; step-size: 1./N[state][action]\n",
    "                self.Q[state][action] += self.discount_factor * ( 1./ self.N[state][action] ) * (returnGt - self.Q[state][action]) \n",
    "                run[f'N0: {self.n0} gamma: {self.gamma} q_value'].log(self.Q[state][action])\n",
    "                self.visited_states.append(state)\n",
    "                \n",
    "        self.visited_states = []\n",
    "        if(self.aux == 1):\n",
    "            self.aux == 0\n",
    "            \n",
    "        # Define new policy with updated Q and N\n",
    "        self.policy = self.update_epsilon_greedy_policy(self.Q, self.n0, self.N)\n",
    "        run[f'N0: {self.n0} gamma: {self.gamma} win_acc'].log(self.n_won_battles/len(self._reward_buffer))\n",
    "        \n",
    "# We evaluate the performance on mon_a against mon_b as its type advantage\n",
    "    def teampreview_performance(self, mon_a, mon_b):    \n",
    "        a_on_b = b_on_a = -np.inf\n",
    "        for type_ in mon_a.types:\n",
    "            if type_:\n",
    "                a_on_b = max(a_on_b, type_.damage_multiplier(*mon_b.types))\n",
    "        # We do the same for mon_b over mon_a\n",
    "        for type_ in mon_b.types:\n",
    "            if type_:\n",
    "                b_on_a = max(b_on_a, type_.damage_multiplier(*mon_a.types))\n",
    "        # Our performance metric is the different between the two\n",
    "        return a_on_b - b_on_a    \n",
    "    \n",
    "    # Teampreview (Before battle starts)\n",
    "    def teampreview(self, battle):\n",
    "        mon_performance = {}\n",
    "\n",
    "        # For each of our pokemons\n",
    "        for i, mon in enumerate(battle.team.values()):\n",
    "            # We store their average performance against the opponent team\n",
    "            mon_performance[i] = np.mean(\n",
    "                [\n",
    "                    self.teampreview_performance(mon, opp)\n",
    "                    for opp in battle.opponent_team.values()\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        # We sort our mons by performance\n",
    "        ordered_mons = sorted(mon_performance, key=lambda k: -mon_performance[k])\n",
    "        \n",
    "        # We start with the one we consider best overall\n",
    "        # We use i + 1 as python indexes start from 0\n",
    "        #  but showdown's indexes start from 1\n",
    "        return \"/team \" + \"\".join([str(i + 1) for i in ordered_mons])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ffcad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_team = \"\"\"\n",
    "Pikachu-Original (M) @ Light Ball  \n",
    "Ability: Static  \n",
    "EVs: 252 Atk / 4 SpD / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Volt Tackle  \n",
    "- Nuzzle  \n",
    "- Iron Tail  \n",
    "- Knock Off  \n",
    "\n",
    "Charizard @ Life Orb  \n",
    "Ability: Solar Power  \n",
    "EVs: 252 SpA / 4 SpD / 252 Spe  \n",
    "Timid Nature  \n",
    "IVs: 0 Atk  \n",
    "- Flamethrower  \n",
    "- Dragon Pulse  \n",
    "- Roost  \n",
    "- Sunny Day  \n",
    "\n",
    "Blastoise @ White Herb  \n",
    "Ability: Torrent  \n",
    "EVs: 4 Atk / 252 SpA / 252 Spe  \n",
    "Mild Nature  \n",
    "- Scald  \n",
    "- Ice Beam  \n",
    "- Earthquake  \n",
    "- Shell Smash  \n",
    "\n",
    "Venusaur @ Black Sludge  \n",
    "Ability: Chlorophyll  \n",
    "EVs: 252 SpA / 4 SpD / 252 Spe  \n",
    "Modest Nature  \n",
    "IVs: 0 Atk  \n",
    "- Giga Drain  \n",
    "- Sludge Bomb  \n",
    "- Sleep Powder  \n",
    "- Leech Seed  \n",
    "\n",
    "Sirfetch’d @ Aguav Berry  \n",
    "Ability: Steadfast  \n",
    "EVs: 248 HP / 252 Atk / 8 SpD  \n",
    "Adamant Nature  \n",
    "- Close Combat  \n",
    "- Swords Dance  \n",
    "- Poison Jab  \n",
    "- Knock Off  \n",
    "\n",
    "Tauros (M) @ Assault Vest  \n",
    "Ability: Intimidate  \n",
    "EVs: 252 Atk / 4 SpD / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Double-Edge  \n",
    "- Earthquake  \n",
    "- Megahorn  \n",
    "- Iron Head  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26f8ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_team = \"\"\"\n",
    "Eevee @ Eviolite  \n",
    "Ability: Adaptability  \n",
    "EVs: 252 HP / 252 Atk / 4 SpD  \n",
    "Adamant Nature  \n",
    "- Quick Attack  \n",
    "- Flail  \n",
    "- Facade  \n",
    "- Wish  \n",
    "\n",
    "Vaporeon @ Leftovers  \n",
    "Ability: Hydration  \n",
    "EVs: 252 HP / 252 Def / 4 SpA  \n",
    "Bold Nature  \n",
    "IVs: 0 Atk  \n",
    "- Scald  \n",
    "- Shadow Ball  \n",
    "- Toxic  \n",
    "- Wish  \n",
    "\n",
    "Sylveon @ Aguav Berry  \n",
    "Ability: Pixilate  \n",
    "EVs: 252 HP / 252 SpA / 4 SpD  \n",
    "Modest Nature  \n",
    "IVs: 0 Atk  \n",
    "- Hyper Voice  \n",
    "- Mystical Fire  \n",
    "- Psyshock  \n",
    "- Calm Mind  \n",
    "\n",
    "Jolteon @ Assault Vest  \n",
    "Ability: Quick Feet  \n",
    "EVs: 252 SpA / 4 SpD / 252 Spe  \n",
    "Timid Nature  \n",
    "IVs: 0 Atk  \n",
    "- Thunderbolt  \n",
    "- Hyper Voice  \n",
    "- Volt Switch  \n",
    "- Shadow Ball  \n",
    "\n",
    "Leafeon @ Life Orb  \n",
    "Ability: Chlorophyll  \n",
    "EVs: 252 Atk / 4 SpD / 252 Spe  \n",
    "Adamant Nature  \n",
    "- Leaf Blade  \n",
    "- Knock Off  \n",
    "- X-Scissor  \n",
    "- Swords Dance  \n",
    "\n",
    "Umbreon @ Iapapa Berry  \n",
    "Ability: Inner Focus  \n",
    "EVs: 252 HP / 4 Atk / 252 SpD  \n",
    "Careful Nature  \n",
    "- Foul Play  \n",
    "- Body Slam  \n",
    "- Toxic  \n",
    "- Wish  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724075fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "342b0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n0_range: N0 values that will be used in our policy function: epsilon = n0/(n0+np.sum(N[state]))\n",
    "# n_battles: list of number of battles (episodes) that will be played.\n",
    "\n",
    "n0_range = [0.1, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.75, 1, 2, 5, 10, 25, 50, 100]\n",
    "gamma_range = [0.01, 0.05, 0.1, 0.2, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "n0_range_array = n0_range*len(gamma_range)\n",
    "gamma_array = gamma_range*len(n0_range)\n",
    "gamma_array\n",
    "n0_range_array.sort()\n",
    "n_battles = [500 for n0 in n0_range_array] #all tests have 100 battles; Can be modified to different values (must have same shape)\n",
    "our_team_array = [our_team for n0 in n0_range_array] #all teams are the same; Can be modified to different teams (must have same shape)\n",
    "op_team_array = [op_team for n0 in n0_range_array] #all opponents are the same; Can be modified to different teams (must have same shape)\n",
    "\n",
    "tests =[ {'n0': n0,\n",
    "          'gamma': gamma,\n",
    "          'n_battles':n_battle,\n",
    "          'team':our_team,\n",
    "          'against':op_team,\n",
    "          'battle_format':\"gen8ou\"}\n",
    "        for n0,gamma,n_battle,our_team,op_team in zip(n0_range_array,gamma_array,n_battles,our_team_array,op_team_array)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819e61be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5ad87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51d8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3a3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    \n",
    "    start = time.time()\n",
    "    run['params'] = test\n",
    "    test['opponent'] = MaxDamagePlayer(battle_format=\"gen8ou\", team=test['against'])\n",
    "    test['player'] = MCPlayer(battle_format=\"gen8ou\", team=test['team'], n0=test['n0'], gamma=test['gamma'])\n",
    "    await test['player'].battle_against(test['opponent'], n_battles=test['n_battles'])\n",
    "    \n",
    "    print(\n",
    "        \"Player with N0=%f and gamma=%f won %d / %d battles [this is %f percent and took %f seconds]\"\n",
    "        % (\n",
    "            round(test['n0'], 2),\n",
    "            round(test['gamma'], 2),\n",
    "            test['player'].n_won_battles,\n",
    "            len(test['player']._reward_buffer),\n",
    "            round(test['player'].n_won_battles/len(test['player']._reward_buffer)*100, 2),\n",
    "            round(time.time() - start, 2)\n",
    "        )\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d975de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c8957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617bccff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0f5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61972d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1327896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to wait until done is True\n",
    "#print(f\"done: {x.done()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a28365",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdfa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "no need with neptune\n",
    "import statistics\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c73d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "no need with neptune\n",
    "for test in tests:\n",
    "\n",
    "    step = 10\n",
    "    exps=range(len(test['player']._reward_buffer))\n",
    "    mean_rewards = []\n",
    "    dv_rewards = []\n",
    "    exps_s = []\n",
    "    mean_rewards.append(0)\n",
    "    dv_rewards.append(0)\n",
    "    exps_s.append(0)\n",
    "\n",
    "    for st in range(step):\n",
    "\n",
    "        n0 = int(st*len(test['player']._reward_buffer)/step)\n",
    "        n1 = int(n0+len(test['player']._reward_buffer)/step)\n",
    "        exps_s.append(n1)\n",
    "        am_rewards = []\n",
    "        max_rewards = 0\n",
    "        max_exp_rew = 0\n",
    "\n",
    "        #if(debug): print(f\"n0: {n0} n1: {n1}\")\n",
    "        for n in range(n0,n1):\n",
    "            #if(debug): print(n)\n",
    "            am_rewards.append(test['player']._reward_buffer[n])\n",
    "            if env_player.all_rewards[n] > max_rewards: \n",
    "                max_rewards = test['player']._reward_buffer[n]\n",
    "                max_exp_rew = exps[n]\n",
    "        mean_rewards.append(int(statistics.mean(am_rewards)))\n",
    "        dv_rewards.append(int(statistics.stdev(am_rewards)))\n",
    "\n",
    "    print(f\"Max. reward: {max_rewards} Exp: {max_exp_rew}\")\n",
    "    #print(exps_s)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "\n",
    "    #fig, axes = plt.subplots(6, 3, figsize=(30, 30))\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Experimento')\n",
    "\n",
    "    #ax1.set_xticks(exps_s)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax1.set_ylabel('Recompensas', color=color)  # we already handled the x-label with ax1\n",
    "    ax1.plot(exps_s, mean_rewards, 'b:') #color=color\n",
    "    plt.fill_between(exps_s,np.array(mean_rewards)-np.array(dv_rewards)/2,np.array(mean_rewards)+np.array(dv_rewards)/2,alpha=.1, color=color)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf5566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462b55a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f41cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779811b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528e5203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Q and N to txt files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "for test in tests:\n",
    "    qstore = test['player'].Q\n",
    "    today_s = str(date.today())\n",
    "    n0_s = str(round(test['n0'],2))\n",
    "    acc_s = str(round(test['player'].n_won_battles/len(test['player']._reward_buffer)*100))\n",
    "    battle_s = str(len(test['player']._reward_buffer))\n",
    "    filename = today_s+\"_Q_MCControl_n0_\"+n0_s+\"_Acc_\"+acc_s+\"_of_\"+battle_s+\"_battles_maxnerf\"\n",
    "    filename_txt=re.sub(r'(?<=\\d)[,\\.-]','',filename)+\".txt\"\n",
    "    file = open(filename_txt, \"w\")\n",
    "    strig = repr(qstore)\n",
    "    file.write(filename +\" \"+ strig + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in tests:\n",
    "    nstore = test['player'].N\n",
    "    today_s = str(date.today())\n",
    "    n0_s = str(round(test['n0'],2))\n",
    "    acc_s = str(round(test['player'].n_won_battles/len(test['player']._reward_buffer)*100))\n",
    "    battle_s = str(len(test['player']._reward_buffer))\n",
    "    filename = today_s+\"_N_MCControl_n0_\"+n0_s+\"_Acc_\"+acc_s+\"_of_\"+battle_s+\"_battles_maxnerf\"\n",
    "    filename_txt=re.sub(r'(?<=\\d)[,\\.-]','',filename)+\".txt\"\n",
    "    file = open(filename_txt, \"w\")\n",
    "    strig = repr(nstore)\n",
    "    file.write(filename +\" \"+ strig + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c959c45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state is 4 moves_base_power, 4 moves_dmg_multiplier, [remaining_mon_team, remaining_mon_opponent]\n",
    "# 3D graph: X: sum(moves_base_power * moves_dmg_multiplier), Y: remaining_mon_team - remaining_mon_opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3754ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not working\n",
    "\"\"\"\n",
    "def plot_value_function(V, z_plot, title=\"Value Function\"):\n",
    "   \n",
    "    min_x = min(k[0] for k in V.keys())\n",
    "    max_x = max(k[0] for k in V.keys())\n",
    "    min_y = min(k[1] for k in V.keys())\n",
    "    max_y = max(k[1] for k in V.keys())\n",
    "\n",
    "    x_range = np.arange(min_x, max_x + 1)\n",
    "    y_range = np.arange(min_y, max_y + 1)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "    # Find value for all (x, y) coordinates\n",
    "    Z = np.apply_along_axis(lambda _: V[(_[0], _[1])], 2, np.dstack([X, Y]))\n",
    "    #Z_ace = np.apply_along_axis(lambda _: V[(_[0], _[1], True)], 2, np.dstack([X, Y]))\n",
    "\n",
    "    def plot_surface(X, Y, Z, title):\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "                               cmap=matplotlib.cm.coolwarm, vmin=-1.0, vmax=1.0)\n",
    "        ax.set_xlabel('sum(moves_base_power * moves_dmg_multiplier)')\n",
    "        ax.set_ylabel('remaining_mon_team - remaining_mon_opponent')\n",
    "        ax.set_zlabel('Value')\n",
    "        ax.set_title(title)\n",
    "        #ax.view_init(ax.elev, -120)\n",
    "        fig.colorbar(surf)\n",
    "        plt.show()\n",
    "\n",
    "    plot_surface(X, Y, z_plot, \"{}\".format(title))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def simple_plot(V, title=\"Value Function\"):\n",
    "    min_x = min(k[0] for k in V.keys())\n",
    "    max_x = max(k[0] for k in V.keys())\n",
    "    min_y = min(k[1] for k in V.keys())\n",
    "    max_y = max(k[1] for k in V.keys())\n",
    "\n",
    "    x_range = np.arange(min_x, max_x + 1)\n",
    "    y_range = np.arange(min_y, max_y + 1)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26298722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data for plotting: Create value function from action-value function\n",
    "# by picking the best action at each state\n",
    "V = defaultdict(float)\n",
    "i = 0\n",
    "\n",
    "for test in tests:\n",
    "    z_values = []\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    for state, actions in test['player'].Q.items():\n",
    "        action_value = np.max(actions)\n",
    "        z_values.append(action_value)\n",
    "        key_float = [float(k) for k in state.split()]\n",
    "        x_emb = key_float[0]*20+key_float[1]*key_float[5]+key_float[2]*key_float[6]+key_float[3]*key_float[7]+key_float[4]*key_float[8]\n",
    "        x_values.append(x_emb)\n",
    "        y_emb = key_float[8]-key_float[9]\n",
    "        y_values.append(y_emb)\n",
    "        V[x_emb,y_emb] = action_value\n",
    "    test[\"vfunction\"] = (x_values, y_values, z_values)\n",
    "#plot_value_function(V, title=\"Optimal Value Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af956b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e31b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9d75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2d834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f635f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a196e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "# create 1D-arrays from the 2D-arrays\n",
    "for test in tests:\n",
    "    x_values, y_values, z_values = test[\"vfunction\"] \n",
    "    z_plot = np.array(z_values).reshape(len(z_values),1)\n",
    "    x_plot = np.array(x_values)\n",
    "    y_plot = np.array(y_values)\n",
    "    xyz = {'x': x_plot, 'y': y_plot, 'z': np.array(z_values)}\n",
    "    df = pd.DataFrame(xyz, index=range(len(xyz['x']))) \n",
    "    x1 = np.linspace(df['x'].min(), df['x'].max(), len(df['x'].unique()))\n",
    "    y1 = np.linspace(df['y'].min(), df['y'].max(), len(df['y'].unique()))\n",
    "    x2, y2 = np.meshgrid(x1, y1)\n",
    "    z2 = griddata((df['x'], df['y']), df['z'], (x2, y2), method='nearest')\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.set_xlabel('index_pokemon*20+sum(moves_base_power * moves_dmg_multiplier)')\n",
    "    ax.set_ylabel('remaining_mon_team - remaining_mon_opponent')\n",
    "    ax.set_zlabel('Value')\n",
    "    ax.set_title('Value - Index for x axis: 0 venusaur;  1*20 pikachuoriginal; 2*20 tauros, 3*20 sirfetchd, 4*20 blastoise, 5*20 charizard')\n",
    "\n",
    "    surf = ax.plot_surface(x2, y2, z2, rstride=1, cstride=1, cmap=matplotlib.cm.coolwarm,\n",
    "        linewidth=0, antialiased=False)\n",
    "    fig.colorbar(surf)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sem index - data for plotting: Create value function from action-value function\n",
    "# by picking the best action at each state\n",
    "V = defaultdict(float)\n",
    "i = 0\n",
    "\n",
    "for test in tests:\n",
    "    z_values = []\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    for state, actions in test['player'].Q.items():\n",
    "        action_value = np.max(actions)\n",
    "        z_values.append(action_value)\n",
    "        key_float = [float(k) for k in state.split()]\n",
    "        x_emb = key_float[1]*key_float[5]+key_float[2]*key_float[6]+key_float[3]*key_float[7]+key_float[4]*key_float[8]\n",
    "        x_values.append(x_emb)\n",
    "        y_emb = key_float[8]-key_float[9]\n",
    "        y_values.append(y_emb)\n",
    "        V[x_emb,y_emb] = action_value\n",
    "    test[\"noindex_function\"] = (x_values, y_values, z_values)\n",
    "#plot_value_function(V, title=\"Optimal Value Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6794fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "# create 1D-arrays from the 2D-arrays\n",
    "for test in tests:\n",
    "    x_values, y_values, z_values = test[\"noindex_function\"] \n",
    "    z_plot = np.array(z_values).reshape(len(z_values),1)\n",
    "    x_plot = np.array(x_values)\n",
    "    y_plot = np.array(y_values)\n",
    "    xyz = {'x': x_plot, 'y': y_plot, 'z': np.array(z_values)}\n",
    "    df = pd.DataFrame(xyz, index=range(len(xyz['x']))) \n",
    "    x1 = np.linspace(df['x'].min(), df['x'].max(), len(df['x'].unique()))\n",
    "    y1 = np.linspace(df['y'].min(), df['y'].max(), len(df['y'].unique()))\n",
    "    x2, y2 = np.meshgrid(x1, y1)\n",
    "    z2 = griddata((df['x'], df['y']), df['z'], (x2, y2), method='nearest')\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.set_xlabel('sum(moves_base_power * moves_dmg_multiplier)')\n",
    "    ax.set_ylabel('remaining_mon_team - remaining_mon_opponent')\n",
    "    ax.set_zlabel('Value')\n",
    "    ax.set_title('Value Function - No index')\n",
    "\n",
    "    surf = ax.plot_surface(x2, y2, z2, rstride=1, cstride=1, cmap=matplotlib.cm.coolwarm,\n",
    "        linewidth=0, antialiased=False)\n",
    "    fig.colorbar(surf)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fdc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too slow and i think is not correct\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "xv, yv = np.meshgrid(x_plot, y_plot)\n",
    "surf = ax.plot_surface(xv, yv, z_plot, rstride=1, cstride=1, cmap=matplotlib.cm.coolwarm, linewidth=0, \n",
    "                                antialiased=False)\n",
    "ax.set_xlabel('sum(moves_base_power * moves_dmg_multiplier)')\n",
    "ax.set_ylabel('remaining_mon_team - remaining_mon_opponent')\n",
    "ax.set_zlabel('Value')\n",
    "ax.set_title('Value Function')\n",
    "fig.colorbar(surf)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc27b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_value_function(V, title=\"Optimal Value Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55266352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80410b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af8865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6690323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify policy. Have to change the observation of Q and N\n",
    "#print(\"Q: \", env_player.Q['0.65 0.7 0.95 0.7 2.0 2.0 1.0 2.0 0.5 0.33'])\n",
    "#print(\"N: \", env_player.N['0.65 0.7 0.95 0.7 2.0 2.0 1.0 2.0 0.5 0.33'])\n",
    "#greedy_action = np.argmax(env_player.Q['0.65 0.7 0.95 0.7 2.0 2.0 1.0 2.0 0.5 0.33'])\n",
    "#dim=env_player.Q['0.65 0.7 0.95 0.7 2.0 2.0 1.0 2.0 0.5 0.33'].shape\n",
    "#observation = '0.65 0.7 0.95 0.7 2.0 2.0 1.0 2.0 0.5 0.33'\n",
    "#env_player.N[observation]\n",
    "#ep = (0.1/(0.1+np.sum(env_player.N[observation])))\n",
    "#probs = np.full(dim, ep / dim[0])\n",
    "#probs\n",
    "#greedy_action = np.argmax(env_player.Q[observation])\n",
    "#probs[greedy_action] += 1 - (0.1/(0.1+np.sum(env_player.N[observation]))) \n",
    "#print(probs)\n",
    "#print(env_player.policy(observation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60da89c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51cb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b9eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10db8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0215ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc047c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for deterministic player (we have to define teams and perform team preview)\n",
    "\n",
    "# We evaluate the performance on mon_a against mon_b as its type advantage\n",
    "    def teampreview_performance(self, mon_a, mon_b):    \n",
    "        a_on_b = b_on_a = -np.inf\n",
    "        for type_ in mon_a.types:\n",
    "            if type_:\n",
    "                a_on_b = max(a_on_b, type_.damage_multiplier(*mon_b.types))\n",
    "        # We do the same for mon_b over mon_a\n",
    "        for type_ in mon_b.types:\n",
    "            if type_:\n",
    "                b_on_a = max(b_on_a, type_.damage_multiplier(*mon_a.types))\n",
    "        # Our performance metric is the different between the two\n",
    "        return a_on_b - b_on_a    \n",
    "    \n",
    "    # Teampreview (Before battle starts)\n",
    "    def teampreview(self, battle):\n",
    "        mon_performance = {}\n",
    "\n",
    "        # For each of our pokemons\n",
    "        for i, mon in enumerate(battle.team.values()):\n",
    "            # We store their average performance against the opponent team\n",
    "            mon_performance[i] = np.mean(\n",
    "                [\n",
    "                    self.teampreview_performance(mon, opp)\n",
    "                    for opp in battle.opponent_team.values()\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # We sort our mons by performance\n",
    "        ordered_mons = sorted(mon_performance, key=lambda k: -mon_performance[k])\n",
    "\n",
    "        # We start with the one we consider best overall\n",
    "        # We use i + 1 as python indexes start from 0\n",
    "        #  but showdown's indexes start from 1\n",
    "        return \"/team \" + \"\".join([str(i + 1) for i in ordered_mons])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
