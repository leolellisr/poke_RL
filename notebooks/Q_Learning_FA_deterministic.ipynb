{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188689e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for training and testing a Player in Pokemon Showdown using Q-Learning with Function Approximation in Deterministic Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comparative Table: https://prnt.sc/1ytqrzm\n",
    "------\n",
    "neptune\n",
    "Action space: 4 moves + 5 switches\n",
    "poke-env installed in C:\\\\Users\\\\-\\\\anaconda3\\\\envs\\\\poke_env\\\\lib\\\\site-packages\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90875d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import matplotlib\n",
    "import neptune.new as neptune\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import date\n",
    "from itertools import product\n",
    "from matplotlib import pyplot\n",
    "from poke_env.environment.abstract_battle import AbstractBattle\n",
    "from poke_env.player.battle_order import ForfeitBattleOrder\n",
    "from poke_env.player.player import Player\n",
    "from scipy.interpolate import griddata\n",
    "from src.PlayerQLearning import Player as PlayerQLearning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global configs\n",
    "\n",
    "debug = True\n",
    "save_to_json_file = True\n",
    "use_validation = False\n",
    "use_neptune = False\n",
    "\n",
    "nest_asyncio.apply()\n",
    "np.random.seed(0)\n",
    "\n",
    "if use_neptune:\n",
    "    run = neptune.init(, project='your_project',\n",
    "                       api_token='your_api_token',\n",
    "                       tags=[\"Q-learning FA deterministic\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3afa6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of agent's team (Pokémon Showdown template)\n",
    "\n",
    "OUR_TEAM = \"\"\"\n",
    "Turtonator @ White Herb  \n",
    "Ability: Shell Armor  \n",
    "EVs: 4 Atk / 252 SpA / 252 Spe  \n",
    "Rash Nature  \n",
    "- Flamethrower  \n",
    "- Dragon Pulse  \n",
    "- Earthquake  \n",
    "- Shell Smash  \n",
    "\n",
    "Lapras @ Leftovers  \n",
    "Ability: Shell Armor  \n",
    "EVs: 252 HP / 252 SpA / 4 SpD  \n",
    "Modest Nature  \n",
    "IVs: 0 Atk  \n",
    "- Freeze-Dry  \n",
    "- Surf  \n",
    "- Thunderbolt  \n",
    "- Toxic  \n",
    "\n",
    "Armaldo @ Assault Vest  \n",
    "Ability: Battle Armor  \n",
    "EVs: 252 HP / 252 Atk / 4 SpD  \n",
    "Adamant Nature  \n",
    "- Earthquake  \n",
    "- Knock Off  \n",
    "- X-Scissor  \n",
    "- Aqua Jet  \n",
    "\n",
    "Drapion @ Life Orb  \n",
    "Ability: Battle Armor  \n",
    "EVs: 252 Atk / 4 SpD / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Poison Jab  \n",
    "- Knock Off  \n",
    "- Earthquake  \n",
    "- X-Scissor  \n",
    "\n",
    "Kabutops @ Aguav Berry  \n",
    "Ability: Battle Armor  \n",
    "EVs: 252 Atk / 4 SpD / 252 Spe  \n",
    "Jolly Nature  \n",
    "- Liquidation  \n",
    "- Leech Life  \n",
    "- Knock Off  \n",
    "- Swords Dance  \n",
    "\n",
    "Falinks @ Iapapa Berry  \n",
    "Ability: Battle Armor  \n",
    "EVs: 252 HP / 252 Atk / 4 SpD  \n",
    "Adamant Nature  \n",
    "- Close Combat  \n",
    "- Poison Jab  \n",
    "- Iron Head  \n",
    "- No Retreat  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaac214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of opponent's team (Pokémon Showdown template)\n",
    "\n",
    "OP_TEAM = \"\"\"\n",
    "Cloyster @ Assault Vest  \n",
    "Ability: Shell Armor  \n",
    "EVs: 248 HP / 252 Atk / 8 SpA  \n",
    "Naughty Nature  \n",
    "- Icicle Spear  \n",
    "- Surf  \n",
    "- Tri Attack  \n",
    "- Poison Jab  \n",
    "\n",
    "Omastar @ White Herb  \n",
    "Ability: Shell Armor  \n",
    "EVs: 252 SpA / 4 SpD / 252 Spe  \n",
    "Modest Nature  \n",
    "IVs: 0 Atk  \n",
    "- Surf  \n",
    "- Ancient Power  \n",
    "- Earth Power  \n",
    "- Shell Smash  \n",
    "\n",
    "Crustle @ Leftovers  \n",
    "Ability: Shell Armor  \n",
    "EVs: 252 HP / 252 Atk / 4 SpD  \n",
    "Adamant Nature  \n",
    "- Earthquake  \n",
    "- Knock Off  \n",
    "- X-Scissor  \n",
    "- Stealth Rock  \n",
    "\n",
    "Escavalier @ Life Orb  \n",
    "Ability: Shell Armor  \n",
    "EVs: 248 HP / 252 Atk / 8 SpD  \n",
    "Adamant Nature  \n",
    "- Knock Off  \n",
    "- Swords Dance  \n",
    "- Iron Head  \n",
    "- Poison Jab  \n",
    "\n",
    "Drednaw @ Aguav Berry  \n",
    "Ability: Shell Armor  \n",
    "EVs: 248 HP / 252 Atk / 8 SpD  \n",
    "Adamant Nature  \n",
    "- Liquidation  \n",
    "- Earthquake  \n",
    "- Poison Jab  \n",
    "- Swords Dance  \n",
    "\n",
    "Type: Null @ Eviolite  \n",
    "Ability: Battle Armor  \n",
    "EVs: 252 HP / 252 Atk / 4 SpD  \n",
    "Adamant Nature  \n",
    "- Facade  \n",
    "- Sleep Talk  \n",
    "- Shadow Claw  \n",
    "- Rest  \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862191ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATE_COMPONENTS = 12\n",
    "# num of features = num of state components + action\n",
    "N_FEATURES = N_STATE_COMPONENTS + 1\n",
    "\n",
    "N_OUR_MOVE_ACTIONS = 4\n",
    "N_OUR_SWITCH_ACTIONS = 5\n",
    "N_OUR_ACTIONS = N_OUR_MOVE_ACTIONS + N_OUR_SWITCH_ACTIONS\n",
    "\n",
    "ALL_OUR_ACTIONS = np.array(range(0, N_OUR_ACTIONS))\n",
    "\n",
    "# Encoding Pokémon Name for ID\n",
    "NAME_TO_ID_DICT = {\n",
    "    \"turtonator\": 0,\n",
    "    \"lapras\": 1,\n",
    "    \"armaldo\": 2,\n",
    "    \"drapion\": 3,\n",
    "    \"kabutops\": 4,\n",
    "    \"falinks\": 5,\n",
    "    \"cloyster\": 0,\n",
    "    \"omastar\": 1,\n",
    "    \"crustle\": 2,\n",
    "    \"escavalier\": 3,\n",
    "    \"drednaw\": 4,\n",
    "    \"typenull\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of MaxDamagePlayer\n",
    "\n",
    "class MaxDamagePlayer(Player):\n",
    "    def choose_move(self, battle):\n",
    "        if battle.available_moves:\n",
    "            best_move = max(battle.available_moves, key=lambda move: move.base_power)\n",
    "            return self.create_order(best_move)\n",
    "        else:\n",
    "            return self.choose_random_move(battle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Q-Learning with Function Approximation Player\n",
    "\n",
    "class QLearningFAPlayer(PlayerQLearning):\n",
    "    def __init__(self, battle_format, team, n0, alpha0, gamma):\n",
    "        super().__init__(battle_format=battle_format, team=team)\n",
    "        self.N = defaultdict(lambda: np.zeros(N_OUR_ACTIONS))\n",
    "        self.w = np.random.rand(N_FEATURES)\n",
    "        self.n0 = n0\n",
    "        self.alpha0 = alpha0\n",
    "        self.gamma = gamma\n",
    "        self.state = None\n",
    "        self.action = None\n",
    "\n",
    "    def choose_move(self, battle):\n",
    "        if self.state is not None:\n",
    "            # observe R, S'\n",
    "            reward = self.compute_reward(battle)\n",
    "            next_state = self.embed_battle(battle)\n",
    "            # Q-learning\n",
    "            self.N[str(self.state)][self.action] += 1\n",
    "            alpha = self.alpha0 / self.N[str(self.state)][self.action]\n",
    "            delta = \\\n",
    "                reward + self.gamma * self.max_q_approx(next_state, self.w) - self.q_approx(self.state, self.action, self.w)\n",
    "            self.w += alpha * delta * self.x(self.state, self.action)\n",
    "            # S <- S'\n",
    "            self.state = next_state\n",
    "        else:\n",
    "            # S first initialization\n",
    "            self.state = self.embed_battle(battle)\n",
    "\n",
    "        # Choose A from S using epsilon-greedy policy\n",
    "        self.action = self.pi(self.state, self.w)\n",
    "\n",
    "        # if the selected action is not possible, perform a random move instead\n",
    "        if self.action == -1:\n",
    "            return ForfeitBattleOrder()\n",
    "        elif self.action < 4 and self.action < len(battle.available_moves) and not battle.force_switch:\n",
    "            return self.create_order(battle.available_moves[self.action])\n",
    "        elif 0 <= self.action - 4 < len(battle.available_switches):\n",
    "            return self.create_order(battle.available_switches[self.action - 4])\n",
    "        else:\n",
    "            return self.choose_random_move(battle)\n",
    "\n",
    "    def _battle_finished_callback(self, battle):\n",
    "        if use_neptune:\n",
    "            run[f'N0: {self.n0} gamma: {self.gamma} win_acc'].log(self.n_won_battles / len(self._reward_buffer))\n",
    "\n",
    "    ''' Helper functions '''\n",
    "\n",
    "    # feature vector\n",
    "    @staticmethod\n",
    "    def x(state, action):\n",
    "        state = np.array(state).astype(float)\n",
    "        return np.append(state, action)\n",
    "\n",
    "    # q^(S, A, W)\n",
    "    def q_approx(self, state, action, w):\n",
    "        state = np.array(state).astype(float)\n",
    "        return np.dot(self.x(state, action), w)\n",
    "\n",
    "    # max(a, q^(S, a', W))\n",
    "    def max_q_approx(self, state, w):\n",
    "        state = np.array(state).astype(float)\n",
    "        return max(np.array([self.q_approx(state, action, w) for action in range(N_OUR_ACTIONS)]))\n",
    "\n",
    "    # epsilon-greedy policy\n",
    "    def pi(self, state, w):\n",
    "        epsilon = self.n0 / (self.n0 + np.sum(self.N[str(state)]))\n",
    "        # let's get the greedy action. Ties must be broken arbitrarily\n",
    "        q_approx = np.array([self.q_approx(state, action, w) for action in range(N_OUR_ACTIONS)])\n",
    "        greedy_action = np.random.choice(np.where(q_approx == q_approx.max())[0])\n",
    "        action_pick_probability = np.full(N_OUR_ACTIONS, epsilon / N_OUR_ACTIONS)\n",
    "        action_pick_probability[greedy_action] += 1 - epsilon\n",
    "        return np.random.choice(ALL_OUR_ACTIONS, p=action_pick_probability)\n",
    "\n",
    "    # the embed battle is our state\n",
    "    # 12 factors: our active mon, opponent's active mon, 4 moves base power, 4 moves multipliers, remaining mons\n",
    "    @staticmethod\n",
    "    def embed_battle(battle):\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                    move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                )\n",
    "\n",
    "        # We count how many pokemons have not fainted in each team\n",
    "        n_fainted_mon_team = (\n",
    "            len([mon for mon in battle.team.values() if mon.fainted])\n",
    "        )\n",
    "        n_fainted_mon_opponent = (\n",
    "            len([mon for mon in battle.opponent_team.values() if mon.fainted])\n",
    "        )\n",
    "\n",
    "        state = list()\n",
    "        state.append(NAME_TO_ID_DICT[str(battle.active_pokemon).split(' ')[0]])\n",
    "        state.append(NAME_TO_ID_DICT[str(battle.opponent_active_pokemon).split(' ')[0]])\n",
    "        for move_base_power in moves_base_power:\n",
    "            state.append('{0:.2f}'.format(move_base_power))\n",
    "        for move_dmg_multiplier in moves_dmg_multiplier:\n",
    "            state.append('{0:.2f}'.format(move_dmg_multiplier))\n",
    "        state.append(n_fainted_mon_team)\n",
    "        state.append(n_fainted_mon_opponent)\n",
    "\n",
    "        return state\n",
    "\n",
    "    # Computing rewards\n",
    "    def reward_computing_helper(\n",
    "            self,\n",
    "            battle: AbstractBattle,\n",
    "            *,\n",
    "            fainted_value: float = 0.15,\n",
    "            hp_value: float = 0.15,\n",
    "            number_of_pokemons: int = 6,\n",
    "            starting_value: float = 0.0,\n",
    "            status_value: float = 0.15,\n",
    "            victory_value: float = 1.0\n",
    "    ) -> float:\n",
    "        # 1st compute\n",
    "        if battle not in self._reward_buffer:\n",
    "            self._reward_buffer[battle] = starting_value\n",
    "        current_value = 0\n",
    "\n",
    "        # Verify if pokemon have fainted or have status\n",
    "        for mon in battle.team.values():\n",
    "            current_value += mon.current_hp_fraction * hp_value\n",
    "            if mon.fainted:\n",
    "                current_value -= fainted_value\n",
    "            elif mon.status is not None:\n",
    "                current_value -= status_value\n",
    "\n",
    "        current_value += (number_of_pokemons - len(battle.team)) * hp_value\n",
    "\n",
    "        # Verify if opponent pokemon have fainted or have status\n",
    "        for mon in battle.opponent_team.values():\n",
    "            current_value -= mon.current_hp_fraction * hp_value\n",
    "            if mon.fainted:\n",
    "                current_value += fainted_value\n",
    "            elif mon.status is not None:\n",
    "                current_value += status_value\n",
    "\n",
    "        current_value -= (number_of_pokemons - len(battle.opponent_team)) * hp_value\n",
    "\n",
    "        # Verify if we won or lost\n",
    "        if battle.won:\n",
    "            current_value += victory_value\n",
    "        elif battle.lost:\n",
    "            current_value -= victory_value\n",
    "\n",
    "        # Value to return\n",
    "        to_return = current_value - self._reward_buffer[battle]\n",
    "        self._reward_buffer[battle] = current_value\n",
    "        if use_neptune:\n",
    "            run[f'N0: {self.n0} gamma: {self.gamma} reward_buffer'].log(current_value)\n",
    "        return to_return\n",
    "\n",
    "    # Calling reward_computing_helper\n",
    "    def compute_reward(self, battle) -> float:\n",
    "        return self.reward_computing_helper(battle, fainted_value=2, hp_value=1, victory_value=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Q-Learning with function approximation validation player\n",
    "\n",
    "class ValidationPlayer(PlayerQLearning):\n",
    "    def __init__(self, battle_format, team, w):\n",
    "        super().__init__(battle_format=battle_format, team=team)\n",
    "        self.w = w\n",
    "\n",
    "    def choose_move(self, battle):\n",
    "        state = self.embed_battle(battle)\n",
    "        # let's get the greedy action. Ties must be broken arbitrarily\n",
    "        q_approx = np.array([self.q_approx(state, action, self.w) for action in range(N_OUR_ACTIONS)])\n",
    "        action = np.random.choice(np.where(q_approx == q_approx.max())[0])\n",
    "\n",
    "        # if the selected action is not possible, perform a random move instead\n",
    "        if action == -1:\n",
    "            return ForfeitBattleOrder()\n",
    "        elif action < 4 and action < len(battle.available_moves) and not battle.force_switch:\n",
    "            return self.create_order(battle.available_moves[action])\n",
    "        elif 0 <= action - 4 < len(battle.available_switches):\n",
    "            return self.create_order(battle.available_switches[action - 4])\n",
    "        else:\n",
    "            return self.choose_random_move(battle)\n",
    "\n",
    "    def _battle_finished_callback(self, battle):\n",
    "        pass\n",
    "\n",
    "    ''' Helper functions '''\n",
    "\n",
    "    # feature vector\n",
    "    @staticmethod\n",
    "    def x(state, action):\n",
    "        state = np.array(state).astype(float)\n",
    "        return np.append(state, action)\n",
    "\n",
    "    # q^(S, A, W)\n",
    "    def q_approx(self, state, action, w):\n",
    "        state = np.array(state).astype(float)\n",
    "        return np.dot(self.x(state, action), w)\n",
    "\n",
    "    # the embed battle is our state\n",
    "    # 12 factors: our active mon, opponent's active mon, 4 moves base power, 4 moves multipliers, remaining mons\n",
    "    @staticmethod\n",
    "    def embed_battle(battle):\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                    move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if move.type:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                )\n",
    "\n",
    "        # We count how many pokemons have not fainted in each team\n",
    "        fainted_mon_team = (\n",
    "            len([mon for mon in battle.team.values() if mon.fainted])\n",
    "        )\n",
    "        fainted_mon_opponent = (\n",
    "            len([mon for mon in battle.opponent_team.values() if mon.fainted])\n",
    "        )\n",
    "\n",
    "        state = list()\n",
    "        state.append(NAME_TO_ID_DICT[str(battle.active_pokemon).split(' ')[0]])\n",
    "        state.append(NAME_TO_ID_DICT[str(battle.opponent_active_pokemon).split(' ')[0]])\n",
    "        for move_base_power in moves_base_power:\n",
    "            state.append('{0:.2f}'.format(move_base_power))\n",
    "        for move_dmg_multiplier in moves_dmg_multiplier:\n",
    "            state.append('{0:.2f}'.format(move_dmg_multiplier))\n",
    "        state.append(fainted_mon_team)\n",
    "        state.append(fainted_mon_opponent)\n",
    "\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477480e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters\n",
    "\n",
    "# possible values for num_battles (number of episodes)\n",
    "n_battles_array = [10000]\n",
    "# exploration schedule from MC, i. e., epsilon(t) = N0 / (N0 + N(S(t)))\n",
    "n0_array = [0.0001, 0.001, 0.01]\n",
    "# possible values for alpha0 (initial learning rate)\n",
    "alpha0_array = [0.01]\n",
    "# possible values for gamma (discount factor)\n",
    "gamma_array = [0.75]\n",
    "\n",
    "\n",
    "list_of_params = [\n",
    "    {\n",
    "        'n_battles': n_battles,\n",
    "        'n0': n0,\n",
    "        'alpha0': alpha0,\n",
    "        'gamma': gamma\n",
    "    } for n_battles, n0, alpha0, gamma in product(n_battles_array, n0_array, alpha0_array, gamma_array)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c00165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json helper functions\n",
    "\n",
    "def save_array_to_json(path_dir, filename, data):\n",
    "    if not os.path.exists(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    full_filename = path_dir + \"/\" + filename\n",
    "    # write\n",
    "    with open(full_filename, \"w\") as file:\n",
    "        json.dump(data if isinstance(data, list) else data.tolist(), file)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "def save_dict_to_json(path_dir, filename, data, append=True):\n",
    "    if not os.path.exists(path_dir):\n",
    "        os.makedirs(path_dir)\n",
    "    full_filename = path_dir + \"/\" + filename\n",
    "    if os.path.exists(full_filename) and append:\n",
    "        with open(full_filename, \"r\") as file:\n",
    "            value_dict = json.load(file)\n",
    "            for key in data:\n",
    "                value_dict[key] = data[key] if isinstance(data[key], list) else data[key].tolist()\n",
    "            file.close()\n",
    "    else:\n",
    "        value_dict = dict()\n",
    "        for key in data:\n",
    "            value_dict[key] = data[key] if isinstance(data[key], list) else data[key].tolist()\n",
    "    # write\n",
    "    with open(full_filename, \"w\") as file:\n",
    "        json.dump(value_dict, file)\n",
    "        file.close()\n",
    "\n",
    "\n",
    "def read_array_from_json(path_dir, filename):\n",
    "    full_filename = path_dir + \"/\" + filename\n",
    "    if not os.path.exists(full_filename):\n",
    "        return None\n",
    "    file = open(full_filename, \"r\")\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_dict_from_json(path_dir, filename):\n",
    "    full_filename = path_dir + \"/\" + filename\n",
    "    if not os.path.exists(full_filename):\n",
    "        return None\n",
    "    file = open(full_filename, \"r\")\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e02e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main (let's battle!)\n",
    "\n",
    "# training\n",
    "async def do_battle_training():\n",
    "    for params in list_of_params:\n",
    "        start = time.time()\n",
    "        params['player'] = QLearningFAPlayer(battle_format=\"gen8ou\", team=OUR_TEAM, n0=params['n0'], alpha0=params['alpha0'], gamma=params['gamma'])\n",
    "        params['opponent'] = MaxDamagePlayer(battle_format=\"gen8ou\", team=OP_TEAM)\n",
    "        await params['player'].battle_against(opponent=params['opponent'], n_battles=params['n_battles'])\n",
    "        if debug:\n",
    "            print(\"training: num battles (episodes)=%d, N0=%.4f, alpha0=%.2f, gamma=%.2f, wins=%d, winning %%=%.2f, total time=%s sec\" %\n",
    "                  (\n",
    "                      params['n_battles'],\n",
    "                      round(params['n0'], 4),\n",
    "                      round(params['alpha0'], 2),\n",
    "                      round(params['gamma'], 2),\n",
    "                      params['player'].n_won_battles,\n",
    "                      round((params['player'].n_won_battles / params['n_battles']) * 100, 2),\n",
    "                      round(time.time() - start, 2)\n",
    "                  ))\n",
    "\n",
    "        # save w to json file\n",
    "        if save_to_json_file:\n",
    "            today_s = str(date.today())\n",
    "            n_battle_s = str(params['n_battles'])\n",
    "            n0_s = str(round(params['n0'], 4))\n",
    "            alpha0_s = str(round(params['alpha0'], 2))\n",
    "            gamma_s = str(round(params['gamma'], 2))\n",
    "            winning_percentage_s = str(round((params['player'].n_won_battles / params['n_battles']) * 100, 2))\n",
    "            filename = \"W_\" + today_s + \"_\" + n_battle_s + \"_\" + n0_s + \"_\" + alpha0_s + \"_\" + gamma_s + \"_\" + winning_percentage_s + \".json\"\n",
    "            save_array_to_json(\"./Q_Learning_FA_det_w\", filename, params['player'].w)\n",
    "\n",
    "        # statistics: key: \"n_battles, n0, alpha0, gamma\", values: list of win or lose\n",
    "        key = str(params['n_battles']) + \"_\" + str(round(params['n0'], 4)) + \"_\" + str(round(params['alpha0'], 2)) + \"_\" + str(round(params['gamma'], 2))\n",
    "        winning_status = list()\n",
    "        for battle in params['player']._battles.values():\n",
    "            if battle.won:\n",
    "                winning_status.append(True)\n",
    "            else:\n",
    "                winning_status.append(False)\n",
    "        # save statistics json file (append)\n",
    "        data = dict()\n",
    "        data[key] = winning_status\n",
    "        save_dict_to_json(\"./Q_Learning_FA_det_statistics\", \"statistics.json\", data)\n",
    "\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(loop.create_task(do_battle_training()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e53921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation - maxPlayer\n",
    "\n",
    "async def do_battle_validation(path_dir):\n",
    "    # read from json\n",
    "    for filename in os.listdir(path_dir):\n",
    "        # learned feature vector\n",
    "        w = np.array(read_array_from_json(path_dir, filename))\n",
    "        # params: n_battles, n0, gamma\n",
    "        params = filename.split(\"_\")\n",
    "        n_battles = int(params[2])\n",
    "        n0 = float(params[3])\n",
    "        alpha0 = float(params[4])\n",
    "        gamma = float(params[5])\n",
    "\n",
    "        # validation (play 1/3 of the battles using Q-learned table)\n",
    "        start = time.time()\n",
    "        validation_player = ValidationPlayer(battle_format=\"gen8ou\", team=OUR_TEAM, w=w)\n",
    "        opponent = MaxDamagePlayer(battle_format=\"gen8ou\", team=OP_TEAM)\n",
    "        n_battles_validation = int(n_battles / 3)\n",
    "        await validation_player.battle_against(opponent=opponent, n_battles=n_battles_validation)\n",
    "        print(\"validation: num battles (episodes)=%d, N0=%.4f, alpha0=%.2f, gamma=%.2f, wins=%d, winning %%=%.2f, total time=%s sec\" %\n",
    "              (\n",
    "                  n_battles_validation,\n",
    "                  n0,\n",
    "                  alpha0,\n",
    "                  gamma,\n",
    "                  validation_player.n_won_battles,\n",
    "                  round((validation_player.n_won_battles / n_battles_validation) * 100, 2),\n",
    "                  round(time.time() - start, 2)\n",
    "              ))\n",
    "\n",
    "\n",
    "if use_validation:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(loop.create_task(do_battle_validation(\"./Q_Learning_FA_det_w\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84035a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation RandomPlayer\n",
    "\n",
    "async def do_battle_validation(path_dir):\n",
    "    # read from json\n",
    "    for filename in os.listdir(path_dir):\n",
    "        # learned feature vector\n",
    "        w = np.array(read_array_from_json(path_dir, filename))\n",
    "        # params: n_battles, n0, gamma\n",
    "        params = filename.split(\"_\")\n",
    "        n_battles = int(params[2])\n",
    "        n0 = float(params[3])\n",
    "        alpha0 = float(params[4])\n",
    "        gamma = float(params[5])\n",
    "\n",
    "        # validation (play 1/3 of the battles using Q-learned table)\n",
    "        start = time.time()\n",
    "        validation_player = ValidationPlayer(battle_format=\"gen8ou\", team=OUR_TEAM, w=w)\n",
    "        opponent = MaxDamagePlayer(battle_format=\"gen8ou\", team=OP_TEAM)\n",
    "        n_battles_validation = int(n_battles / 3)\n",
    "        await validation_player.battle_against(opponent=opponent, n_battles=n_battles_validation)\n",
    "        print(\"validation: num battles (episodes)=%d, N0=%.4f, alpha0=%.2f, gamma=%.2f, wins=%d, winning %%=%.2f, total time=%s sec\" %\n",
    "              (\n",
    "                  n_battles_validation,\n",
    "                  n0,\n",
    "                  alpha0,\n",
    "                  gamma,\n",
    "                  validation_player.n_won_battles,\n",
    "                  round((validation_player.n_won_battles / n_battles_validation) * 100, 2),\n",
    "                  round(time.time() - start, 2)\n",
    "              ))\n",
    "\n",
    "\n",
    "if use_validation:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(loop.create_task(do_battle_validation(\"./Q_Learning_FA_det_w\")))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
